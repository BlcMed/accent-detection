{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from load_config import load_constants_from_yaml\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = load_constants_from_yaml('../constants.yml')\n",
    "\n",
    "SAMPLING_RATING = constants[\"SAMPLING_RATING\"]\n",
    "FRAME_LENGTH_ENERGY = constants[\"FRAME_LENGTH_ENERGY\"]\n",
    "THRESHOLD_PERCENTAGE = constants[\"THRESHOLD_PERCENTAGE\"]\n",
    "MIN_SILENCE_DURATION = constants[\"MIN_SILENCE_DURATION\"]\n",
    "HOP_LENGTH = constants[\"HOP_LENGTH\"]\n",
    "TEST_SIZE = 0.2\n",
    "FIRST_LAYER_NEURONS = 128\n",
    "SECOND_LAYER_NEURONS = 64\n",
    "RANDOM_STATE = 42\n",
    "processed_data_path = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(processed_data_path+\"df_transformed.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "#segmented_mfccs = np.load(processed_data_path+\"segmented_mfccs.npy\")\n",
    "#onehot_labels = np.load(processed_data_path+\"segmented_onehot_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english</td>\n",
       "      <td>-637.64417</td>\n",
       "      <td>28.056667</td>\n",
       "      <td>25.881245</td>\n",
       "      <td>22.617520</td>\n",
       "      <td>18.732693</td>\n",
       "      <td>14.747160</td>\n",
       "      <td>11.137844</td>\n",
       "      <td>8.256512</td>\n",
       "      <td>6.279685</td>\n",
       "      <td>5.198760</td>\n",
       "      <td>4.849034</td>\n",
       "      <td>4.967811</td>\n",
       "      <td>5.265425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>-645.17910</td>\n",
       "      <td>17.923923</td>\n",
       "      <td>17.226955</td>\n",
       "      <td>16.143120</td>\n",
       "      <td>14.777039</td>\n",
       "      <td>13.253267</td>\n",
       "      <td>11.699085</td>\n",
       "      <td>10.227979</td>\n",
       "      <td>8.926468</td>\n",
       "      <td>7.846347</td>\n",
       "      <td>7.002743</td>\n",
       "      <td>6.378356</td>\n",
       "      <td>5.931872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english</td>\n",
       "      <td>-655.15020</td>\n",
       "      <td>4.062725</td>\n",
       "      <td>4.061807</td>\n",
       "      <td>4.060277</td>\n",
       "      <td>4.058136</td>\n",
       "      <td>4.055384</td>\n",
       "      <td>4.052021</td>\n",
       "      <td>4.048049</td>\n",
       "      <td>4.043466</td>\n",
       "      <td>4.038274</td>\n",
       "      <td>4.032475</td>\n",
       "      <td>4.026067</td>\n",
       "      <td>4.019054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>-655.15090</td>\n",
       "      <td>4.061788</td>\n",
       "      <td>4.060869</td>\n",
       "      <td>4.059341</td>\n",
       "      <td>4.057201</td>\n",
       "      <td>4.054449</td>\n",
       "      <td>4.051086</td>\n",
       "      <td>4.047115</td>\n",
       "      <td>4.042531</td>\n",
       "      <td>4.037343</td>\n",
       "      <td>4.031544</td>\n",
       "      <td>4.025139</td>\n",
       "      <td>4.018128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english</td>\n",
       "      <td>-655.15125</td>\n",
       "      <td>4.061337</td>\n",
       "      <td>4.060420</td>\n",
       "      <td>4.058890</td>\n",
       "      <td>4.056751</td>\n",
       "      <td>4.053999</td>\n",
       "      <td>4.050637</td>\n",
       "      <td>4.046666</td>\n",
       "      <td>4.042084</td>\n",
       "      <td>4.036895</td>\n",
       "      <td>4.031097</td>\n",
       "      <td>4.024692</td>\n",
       "      <td>4.017683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels     mfcc_1     mfcc_2     mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0  english -637.64417  28.056667  25.881245  22.617520  18.732693  14.747160   \n",
       "1  english -645.17910  17.923923  17.226955  16.143120  14.777039  13.253267   \n",
       "2  english -655.15020   4.062725   4.061807   4.060277   4.058136   4.055384   \n",
       "3  english -655.15090   4.061788   4.060869   4.059341   4.057201   4.054449   \n",
       "4  english -655.15125   4.061337   4.060420   4.058890   4.056751   4.053999   \n",
       "\n",
       "      mfcc_7     mfcc_8    mfcc_9   mfcc_10   mfcc_11   mfcc_12   mfcc_13  \n",
       "0  11.137844   8.256512  6.279685  5.198760  4.849034  4.967811  5.265425  \n",
       "1  11.699085  10.227979  8.926468  7.846347  7.002743  6.378356  5.931872  \n",
       "2   4.052021   4.048049  4.043466  4.038274  4.032475  4.026067  4.019054  \n",
       "3   4.051086   4.047115  4.042531  4.037343  4.031544  4.025139  4.018128  \n",
       "4   4.050637   4.046666  4.042084  4.036895  4.031097  4.024692  4.017683  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train is your array of labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X = df.drop(\"labels\", axis=1)\n",
    "y = df[\"labels\"]\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # Input shape based on MFCC features\n",
    "    layers.Input(shape=X_train.shape[1:]),\n",
    "    layers.Flatten(),  # Flatten the input\n",
    "    # Dense layer with ReLU activation\n",
    "    layers.Dense(FIRST_LAYER_NEURONS, activation='relu'),\n",
    "    # Dense layer with ReLU activation\n",
    "    layers.Dense(SECOND_LAYER_NEURONS, activation='relu'),\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuphead/Projects/accent-detection/venv/lib/python3.10/site-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11238/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6070 - loss: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuphead/Projects/accent-detection/venv/lib/python3.10/site-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8ms/step - accuracy: 0.6078 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - accuracy: 0.6063 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 5ms/step - accuracy: 0.6075 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 8ms/step - accuracy: 0.6085 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 16ms/step - accuracy: 0.6086 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.6077 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 5ms/step - accuracy: 0.6074 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - accuracy: 0.6072 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m11240/11240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 9ms/step - accuracy: 0.6080 - loss: 0.0000e+00 - val_accuracy: 0.6064 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e467d5019c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14050/14050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - accuracy: 0.6071 - loss: 0.0000e+00\n",
      "Train loss: 0.0\n",
      "Train accuracy: 0.6072508692741394\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Train accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3513/3513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.6098 - loss: 0.0000e+00\n",
      "Test Loss: 0.0\n",
      "Test Accuracy: 0.6092995405197144\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
