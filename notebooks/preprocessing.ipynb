{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from extract_features import *\n",
    "from visualize_audio import *\n",
    "from prepare_data import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATING = 22050\n",
    "FRAME_LENGTH_ENERGY = 2048  # 512\n",
    "THRESHOLD_PERCENTAGE = 0.01  # percentage of max energy\n",
    "MIN_SILENCE_DURATION = 1  # in seconds\n",
    "\n",
    "# n_fft=512 # the window size\n",
    "HOP_LENGTH = 512  # the number of samples between successive frames\n",
    "SEGMENT_DURATION = 0.025  # in seceonds\n",
    "SEGMENT_OVERLAP = 0.01  # in seceonds\n",
    "N_MFCC = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all audio files with the corresponding labels (accents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3 unique labels: {'french', 'korean', 'english'}\n",
      "there are 165 audio files\n"
     ]
    }
   ],
   "source": [
    "audio_data, raw_labels = load_audio_files(\"../data/raw/recordings/\", sr=SAMPLING_RATING)\n",
    "unique_labels=set(raw_labels)\n",
    "print(f'there are {len(unique_labels)} unique labels: {unique_labels}')\n",
    "print(f'there are {len(audio_data)} audio files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to numerical format using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'french',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english',\n",
       " 'english',\n",
       " 'french',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'english',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'french',\n",
       " 'french',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'korean',\n",
       " 'french',\n",
       " 'english',\n",
       " 'korean',\n",
       " 'english',\n",
       " 'english']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 1, 2, 1, 1,\n",
       "       0, 2, 0, 1, 2, 0, 1, 0, 0, 1, 1, 0, 1, 2, 2, 2, 0, 2, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 0, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 1, 1,\n",
       "       2, 1, 0, 2, 2, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 0, 1, 2, 0, 0, 2, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1,\n",
       "       1, 1, 2, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "       1, 1, 2, 0, 2, 2, 1, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>  :  (165,)\n"
     ]
    }
   ],
   "source": [
    "print(type(labels),' : ', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim silence part and store all segments as individual audios with the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trim silence part and store all segments as individual audios with the corresponding labels\n",
    "audio_data_trimmed = []\n",
    "labels_trimmed = []\n",
    "for i, audio in enumerate(audio_data):\n",
    "    audible_segments = split_audio_by_silence(\n",
    "        audio,\n",
    "        SAMPLING_RATING,\n",
    "        threshold_percentage=THRESHOLD_PERCENTAGE,\n",
    "        min_silence_duration=MIN_SILENCE_DURATION,\n",
    "    )\n",
    "    audio_data_trimmed.extend(audible_segments)\n",
    "    labels_trimmed.extend([labels[i]] * len(audible_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1)\n"
     ]
    }
   ],
   "source": [
    "labels_trimmed=np.array(labels_trimmed)\n",
    "labels_trimmed=labels_trimmed.reshape(len(labels_trimmed), 1)\n",
    "print(labels_trimmed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segment audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment audio data\n",
    "\n",
    "# audio_data_segmented = []\n",
    "# labels_segmented = []\n",
    "# for i, audio in enumerate(audio_data_trimmed):\n",
    "#     segments = segment_audio(\n",
    "#         audio, SAMPLING_RATING, duration=SEGMENT_DURATION, overlap=SEGMENT_OVERLAP\n",
    "#     )\n",
    "#     audio_data_segmented.extend(segments)\n",
    "#     labels_segmented.extend([labels_trimmed[i]] * len(segments))\n",
    "#     # for j, segment in enumerate(segments):\n",
    "#     #     np.save(f\"../data/processed/segments/{labels_trimmed[i]}_{i}_{j}.npy\", segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"there are {len(audio_data_segmented)} segments .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract MFCC features from trimmed audio data, not on segmented audio data \n",
    "# because the function itself will split the audio data into segments\n",
    "mfccs = []\n",
    "for audio in audio_data_trimmed:\n",
    "    mfcc = compute_mfcc(\n",
    "        audio, SAMPLING_RATING, n_mfcc=  N_MFCC, duration=SEGMENT_DURATION, overlap=SEGMENT_OVERLAP\n",
    "    )\n",
    "    mfccs.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(mfccs): 175\n",
      "num_segments for mfccs[0]: 2318\n",
      "num_segments for mfccs[5]: 2259\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(mfccs): {len(mfccs)}\")\n",
    "print(f\"num_segments for mfccs[0]: {mfccs[0].shape[1]}\")\n",
    "print(f\"num_segments for mfccs[5]: {mfccs[5].shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform one-hot encoding on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_labels = onehot_encoder.fit_transform(labels_trimmed).toarray() # toarray() is  to convert the sparse matrix to a dense array\n",
    "onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical format using label encoding\n",
    "#label_encoder = LabelEncoder()\n",
    "#encoded_labels_tr = label_encoder.fit_transform(labels_trimmed)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "#onehot_encoder = OneHotEncoder()\n",
    "#encoded_labels_tr = encoded_labels_tr.reshape(len(encoded_labels_tr), 1)\n",
    "#onehot_labels_tr = onehot_encoder.fit_transform(encoded_labels_tr).toarray() # toarray() is  to convert the sparse matrix to a dense array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we want to split the mfccs into segments with the corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize lists to store segments and their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_mfccs = []\n",
    "segmented_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over each audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mfcc in enumerate(mfccs):\n",
    "    # Get the shape of MFCCs and label for the current audio\n",
    "    mfcc_shape = mfcc.shape\n",
    "    label = labels_trimmed[i]\n",
    "\n",
    "    # Extract the number of segments and the number of frames per segment\n",
    "    num_segments = mfcc.shape[1]  # Second dimension of the MFCC shape\n",
    "\n",
    "    # Iterate over each segment in the current audio\n",
    "    for j in range(num_segments):\n",
    "        # Extract the MFCCs for the current segment\n",
    "        mfcc_segment = mfccs[i][:, j]\n",
    "\n",
    "        # Append the segment and its corresponding label to the lists\n",
    "        segmented_mfccs.append(mfcc_segment)\n",
    "        segmented_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(segmented_mfccs): 451528\n",
      "len(segmented_labels): 451528\n",
      "segmented_mfccs[0]: 13\n",
      "segmented_labels[0]: [0]\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists to NumPy arrays\n",
    "# segmented_mfccs = np.array(segmented_mfccs)\n",
    "# segmented_labels = np.array(segmented_labels)\n",
    "\n",
    "print(f\"len(segmented_mfccs): {len(segmented_mfccs)}\")\n",
    "print(f\"len(segmented_labels): {len(segmented_labels)}\")\n",
    "print(f\"segmented_mfccs[0]: {len(segmented_mfccs[0])}\")\n",
    "print(f\"segmented_labels[0]: {segmented_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_labels = np.array(segmented_labels)\n",
    "segmented_labels = segmented_labels.reshape(len(segmented_labels), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform One-Hot Encoding labels on splitted MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding\n",
    "onehot_encoder_segmentation = OneHotEncoder()\n",
    "segmented_onehot_labels = onehot_encoder_segmentation.fit_transform(segmented_labels).toarray() # toarray() is  to convert the sparse matrix to a dense array\n",
    "\n",
    "print(segmented_onehot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def save_arrays_to_hdf5(arrays, file_path):\n",
    "    with h5py.File(file_path, 'w') as hf:\n",
    "        for i, arr in enumerate(arrays):\n",
    "            dataset_name = f'array_{i}'\n",
    "            hf.create_dataset(dataset_name, data=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save audio data after trimming silence parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(processed_data_path + 'audio_data_trimmed.npy', audio_data_trimmed)\n",
    "save_arrays_to_hdf5(audio_data_trimmed, processed_data_path + 'audio_data_trimmed.h5')\n",
    "np.save(processed_data_path + 'labels_trimmed.npy', labels_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save MFCCs and the labels One-Hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(processed_data_path + 'mfccs.npy', mfccs)\n",
    "save_arrays_to_hdf5(mfccs, processed_data_path + 'mfccs.h5')\n",
    "np.save(processed_data_path + 'onehot_labels.npy', onehot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save segmented MFCC features and the corresponding labels one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(processed_data_path + 'segmented_mfccs.npy', segmented_mfccs)\n",
    "np.save(processed_data_path + 'segmented_onehot_labels.npy', segmented_onehot_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
